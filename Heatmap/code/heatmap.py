# -*- coding: utf-8 -*-
"""Heatmap.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/172xB2yKMlpli1FKxMtXKJZhbfSCf_5zL
"""

from google.colab import drive
drive.mount('/content/drive')

!unzip "/content/drive/MyDrive/dataset.zip"

# -------------------------------------------------------------------
# 各種ライブラリのインポート
# -------------------------------------------------------------------
import os
import cv2

# 定数の定義
DATADIR = "./dataset"
MODEL_DIR = "/content/drive/MyDrive"
CATEGORIES = ["saga", "others"]
# ここで元の画像サイズを使用
# IMG_SIZE = 150
IMG_SIZE = 300
IMG_SIZE_2=200


# データセットを定義
training_data = []

# 画像を読込み、データセットを設定
for class_num, category in enumerate(CATEGORIES):
    path = os.path.join(DATADIR, category)
    for image_name in os.listdir(path):
        try:
            img_array = cv2.imread(os.path.join(path, image_name))
            img_resize_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE_2))  # 画像のリサイズ（200✕300）
            training_data.append([img_resize_array, class_num])
        except Exception as e:
            pass

import numpy as np
import random
from sklearn import model_selection

from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
import matplotlib.pyplot as plt
from tensorflow.keras import regularizers

TRAIN_SIZE = 540
TEST_SIZE = 134
BATCH_SIZE = 8
EPOCHS =100
# 正規化を行う関数：Xを0～1に変換する
def normalize(x):
    x_max = np.max(x)
    x_min = np.min(x)
    return (x - x_min) / (x_max - x_min)

# 画像の前加工
random.shuffle(training_data)
X_train = []
Y_train = []

for feature, label in training_data:
    X_train.append(feature)
    Y_train.append(label)

X_train = np.array(X_train)
Y_train = np.array(Y_train)

# データセットの確認(サンプルで４つだけ)
for i in range(0, 4):
    print("学習データのラベル：", Y_train[i])
    plt.subplot(2, 2, i+1)
    plt.axis('off')
    plt.title('saga' if Y_train[i] == 0 else 'others')
    plt.imshow(X_train[i], cmap='gray')
plt.show()

#データセットを訓練データ(346)とテストデータ(150)に分割
t = model_selection.train_test_split(X_train, Y_train, train_size=TRAIN_SIZE, test_size=TEST_SIZE)
train_feature, test_feature, train_label, test_label = t

#訓練データとテストデータを正規化（0～1の値に揃える）
train_feature = normalize(train_feature)
test_feature = normalize(test_feature)

# モデル作成・訓練・テスト
model = Sequential()
# モデルの定義
# 入力－畳込み層－全結合層－出力(2:softmax)
# 畳込み層 フィルタ（３✕３）を32枚　0パティングで入力と出力サイズが同じ　入力の形（元の画像サイズ✕3）
model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(IMG_SIZE_2, IMG_SIZE,3)))
model.add(layers.Conv2D(32, (3, 3), activation='relu'))
model.add(layers.MaxPool2D(pool_size=(2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(256, activation='relu',kernel_regularizer=regularizers.l1(0.001)))
model.add(layers.Dense(2, activation='softmax'))
model.add(layers.Dropout(0.5))  # ドロップアウト率は適宜調整してください
# 最適化アルゴリズム、損失関数、評価関数のリスト設定
model.compile(
  optimizer='adam',
  loss='sparse_categorical_crossentropy',
  metrics=['accuracy']
)

# モデルを学習させる
history = model.fit(train_feature, train_label, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(test_feature, test_label))

# 学習履歴の可視化・グラフ表示（accuracy）
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.grid()
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

# 学習履歴の可視化・グラフ表示（loss）
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('loss')
plt.xlabel('Epoch')
plt.grid()
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

# モデルの損失値と評価値を返す（テストデータ）
score = model.evaluate(test_feature, test_label, verbose=2)

# テストデータの損失値と評価値をプリント
print('Test loss:', score[0])
print('Test accuracy:', score[1])

model.summary()#ここで、毎回最後の畳み込み層の名前を確認

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D, Input
import numpy as np

# モデルの定義
input_tensor = Input(shape=(200, 300, 3))
x = Conv2D(32, (3, 3), activation='relu', name='conv2d_1')(input_tensor)#ここでフィルタの種類conv2d_○を決める
model = Model(inputs=input_tensor, outputs=x)

# モデルをダミーデータで呼び出してレイヤーを初期化
dummy_input = np.random.random((1, 200,300, 3))
model(dummy_input)  # モデルを呼び出すことでレイヤーの入力が定義される

print("モデルが正常に呼び出されました。")

#ヒートマップ数値表示

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Model

last_conv_layer_name = "conv2d_1"

# アクティベーションモデルの作成
activation_model = Model(inputs=model.input, outputs=model.get_layer(last_conv_layer_name).output)

# テスト画像を取得（200x300の画像）
test_image = test_feature[92]  # test_featureが200x300の画像データを含んでいることを確認

# テスト画像をモデルに入力してアクティベーションを取得
activation = activation_model.predict(np.expand_dims(test_image, axis=0))

# ヒートマップの計算
heatmap = activation[0]

# 特徴マップのチャネルを平均化
heatmap = np.mean(heatmap, axis=-1)  # チャネルを平均化して2次元にする

# 8x8のブロックごとに合計を計算
block_size = 10
h_blocks = heatmap.shape[0] // block_size
w_blocks = heatmap.shape[1] // block_size

# 合計を格納するための新しい行列を初期化
summed_heatmap = np.zeros((h_blocks, w_blocks))

for i in range(h_blocks):
    for j in range(w_blocks):
        block = heatmap[i * block_size:(i + 1) * block_size, j * block_size:(j + 1) * block_size]
        summed_heatmap[i, j] = np.sum(block)

# ヒートマップの可視化
plt.figure(figsize=(10, 8))
plt.imshow(heatmap, cmap='viridis', aspect='auto')

# 合計値をヒートマップ上に表示（0.0の場合は表示しない）
for i in range(h_blocks):
    for j in range(w_blocks):
        value = summed_heatmap[i, j]
        if value != 0.0:  # 0.0の場合は表示しない
            # 小数第1位まで表示
            formatted_value = f'{value:.1f}'  # 小数第1位までのフォーマット
            plt.text(j * block_size + block_size / 2, i * block_size + block_size / 2,
                     formatted_value, ha='center', va='center', fontsize=7.5, color='white')

plt.title('Activation Map with 10×10 Block Sums (200x300 Pixels)')
plt.colorbar()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Model

last_conv_layer_name = "conv2d_1"

# アクティベーションモデルの作成
activation_model = Model(inputs=model.input, outputs=model.get_layer(last_conv_layer_name).output)

# テスト画像を取得
num_images = len(test_feature)
cols = 5  # 一行に表示する画像の枚数
rows = (num_images + cols - 1) // cols  # 必要な行数

# ヒートマップを計算する関数
def calculate_heatmap(image):
    activation = activation_model.predict(np.expand_dims(image, axis=0))
    heatmap = activation[0]
    heatmap = np.mean(heatmap, axis=-1)  # チャネルを平均化して2次元にする
    return heatmap

# ヒートマップを表示する関数
def display_heatmap_with_values(heatmap, block_size):
    # 8x8のブロックごとに合計を計算
    h_blocks = heatmap.shape[0] // block_size
    w_blocks = heatmap.shape[1] // block_size

    # 合計を格納するための新しい行列を初期化
    summed_heatmap = np.zeros((h_blocks, w_blocks))

    for i in range(h_blocks):
        for j in range(w_blocks):
            block = heatmap[i * block_size:(i + 1) * block_size, j * block_size:(j + 1) * block_size]
            summed_heatmap[i, j] = np.sum(block)

    return heatmap, summed_heatmap

# 複数のテストデータとそのヒートマップを表示する
block_size = 10  # ブロックサイズを設定
plt.figure(figsize=(15, 3 * rows))

for i in range(num_images):
    test_image = test_feature[i]
    heatmap = calculate_heatmap(test_image)
    heatmap, summed_heatmap = display_heatmap_with_values(heatmap, block_size)

    # 元の画像を表示
    plt.subplot(rows, cols * 2, i * 2 + 1)
    plt.imshow(test_image, cmap='gray')
    plt.title(f'Image {i}')
    plt.axis('off')

    # ヒートマップを表示
    plt.subplot(rows, cols * 2, i * 2 + 2)
    plt.imshow(heatmap, cmap='viridis', aspect='auto')

    # 合計値をヒートマップ上に表示（0.0の場合は表示しない）
    for j in range(summed_heatmap.shape[0]):
        for k in range(summed_heatmap.shape[1]):
            value = summed_heatmap[j, k]
            if value != 0.0:  # 0.0の場合は表示しない
                formatted_value = f'{value:.1f}'  # 小数第1位までのフォーマット
                plt.text(k * block_size + block_size / 2, j * block_size + block_size / 2,
                         formatted_value, ha='center', va='center', fontsize=8, color='white')

    plt.title(f'Heatmap {i}')
    plt.axis('off')

plt.tight_layout()
plt.show()

#個別でダウンロード用
import tensorflow as tf
from tensorflow.keras.models import Model

last_conv_layer_name="conv2d_1"##ここを先ほど調べた数字に変える(conv2d_○○)

# 最後の畳み込み層の出力を取得するための新しいモデルを作成
activation_model = Model(inputs=model.input, outputs=model.get_layer(last_conv_layer_name).output)

# テスト画像を取得（例として最初の画像を使用）
test_image = test_feature[87
                          ]

print(str(test_feature[80]))


print()

# テスト画像をモデルに入力して最後の畳み込み層の出力を取得
activation = activation_model.predict(np.expand_dims(test_image, axis=0))

# 出力の形状を取得
activation_shape = activation.shape

# 出力の特徴マップの平均値を計算
heatmap = np.mean(activation, axis=-1)

# ヒートマップの可視化
plt.imshow(heatmap[0], cmap='coolwarm')#cmapでヒートマップの種類決めれる
plt.title('Activation Map')
plt.colorbar()
plt.show()

#すべてのヒートマップの結果を表示
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Model

# 最後の畳み込み層の名前
last_conv_layer_name = "conv2d_1"  # モデルの最後の畳み込み層の名前に合わせてください

# 最後の畳み込み層の出力を取得するための新しいモデルを作成
activation_model = Model(inputs=model.input, outputs=model.get_layer(last_conv_layer_name).output)

# テストデータのヒートマップを生成する関数
def generate_heatmaps(images, model):
    heatmaps = []
    for image in images:
        # 画像をモデルに入力して最後の畳み込み層の出力を取得
        activation = model.predict(np.expand_dims(image, axis=0))

        # 出力の特徴マップの平均値を計算
        heatmap = np.mean(activation, axis=-1)[0]
        heatmaps.append(heatmap)
    return heatmaps

# テストデータのヒートマップを生成
heatmaps = generate_heatmaps(test_feature, activation_model)

# 複数のテストデータとそのヒートマップを表示する
num_images = len(test_feature)
cols = 5  # 一行に表示する画像の枚数
rows = (num_images + cols - 1) // cols  # 必要な行数

plt.figure(figsize=(15, 3 * rows))

for i in range(num_images):
    # 元の画像を表示
    plt.subplot(rows, cols * 2, i * 2 + 1)
    plt.imshow(test_feature[i], cmap='gray')
    plt.title(f'Image {i}')
    plt.axis('off')

    # ヒートマップを表示
    plt.subplot(rows, cols * 2, i * 2 + 2)
    plt.imshow(heatmaps[i], cmap='viridis')
    plt.title(f'Heatmap {i}')
    plt.axis('off')

plt.tight_layout()
plt.show()